{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zce7DecpABq2",
        "outputId": "f684cc98-7628-4140-c113-155663fdd6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting streamlit-authenticator\n",
            "  Downloading streamlit_authenticator-0.4.2-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.9.2-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Collecting bcrypt>=3.1.7 (from streamlit-authenticator)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting captcha>=0.5.0 (from streamlit-authenticator)\n",
            "  Downloading captcha-0.7.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: cryptography>=42.0.5 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (43.0.3)\n",
            "Collecting extra-streamlit-components>=0.1.70 (from streamlit-authenticator)\n",
            "  Downloading extra_streamlit_components-0.1.81-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: PyJWT>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-authenticator) (2.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Collecting unsloth_zoo>=2025.9.3 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.9.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets<4.0.0,>=3.4.1 (from unsloth)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
            "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=42.0.5->streamlit-authenticator) (1.17.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.9.3->unsloth) (0.10.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.9.3->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.9.3->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=42.0.5->streamlit-authenticator) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading streamlit_authenticator-0.4.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.9.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading captcha-0.7.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading extra_streamlit_components-0.1.81-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.22.2-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.9.3-py3-none-any.whl (205 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shtab, pyngrok, msgspec, captcha, bcrypt, pydeck, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, streamlit, unsloth_zoo, extra-streamlit-components, unsloth, streamlit-authenticator\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed bcrypt-4.3.0 bitsandbytes-0.47.0 captcha-0.7.1 cut_cross_entropy-25.1.1 datasets-3.6.0 extra-streamlit-components-0.1.81 msgspec-0.19.0 pydeck-0.9.1 pyngrok-7.3.0 shtab-1.7.2 streamlit-1.49.1 streamlit-authenticator-0.4.2 trl-0.22.2 tyro-0.9.31 unsloth-2025.9.2 unsloth_zoo-2025.9.3 xformers-0.0.32.post2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok streamlit-authenticator pyyaml transformers peft torch unsloth pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxD55RHAqKG",
        "outputId": "6838e4d5-755c-49bc-f069-354dbae65822"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile AdaptiveBehaviorSocraticTutor.py\n",
        "import streamlit as st\n",
        "import streamlit_authenticator as stauth\n",
        "import yaml\n",
        "from yaml.loader import SafeLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import time\n",
        "from unsloth import FastLanguageModel\n",
        "from google.colab import drive\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL, END-TO-END SOCRATIC TUTOR APPLICATION\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Page Configuration ---\n",
        "st.set_page_config(page_title=\"Adaptive Socratic AI Tutor\", layout=\"wide\")\n",
        "\n",
        "#QUESTION_BANK\n",
        "QUESTION_BANK = [\n",
        "    {\"id\": \"q1\", \"latex\": r'''\\text{1. A rectangle has a length of } 8 \\text{ cm and a width of } 5 \\text{ cm. What is its area?}''', \"text\": \"A rectangle has a length of 8 cm and a width of 5 cm. What is its area?\", \"answer\": 40, \"skill\": \"area\", \"problemType\": \"algebra\", \"hint\": \"The area of a rectangle is calculated by multiplying its length by its width.\"},\n",
        "    {\"id\": \"q2\", \"latex\": r'''\\text{2. If a train travels at } 60 \\text{ km/h, how far will it travel in } 3 \\text{ hours?}''', \"text\": \"If a train travels at 60 km/h, how far will it travel in 3 hours?\", \"answer\": 180, \"skill\": \"distance-rate-time\", \"problemType\": \"word-problem\", \"hint\": \"Distance = Speed Ã— Time.\"},\n",
        "    {\"id\": \"q3\", \"latex\": r'''\\text{3. What is the value of x in the equation } 2x + 5 = 15?''', \"text\": \"What is the value of x in the equation 2x + 5 = 15?\", \"answer\": 5, \"skill\": \"solving-linear-equations\", \"problemType\": \"algebra\", \"hint\": \"First, isolate the term with 'x' by subtracting 5 from both sides.\"},\n",
        "    {\"id\": \"q4\", \"latex\": r'''\\text{4. A pizza is cut into 8 equal slices. If you eat 3 slices, what fraction is left? (Answer as a decimal)}''', \"text\": \"A pizza is cut into 8 equal slices. If you eat 3 slices, what fraction is left? (Answer as a decimal)\", \"answer\": 0.625, \"skill\": \"fractions\", \"problemType\": \"word-problem\", \"hint\": \"If you eat 3 slices, how many are left out of the original 8? Convert that fraction to a decimal.\"},\n",
        "    {\"id\": \"q5\", \"latex\": r'''\\text{5. What is } 15\\% \\text{ of } 200?''', \"text\": \"What is 15% of 200?\", \"answer\": 30, \"skill\": \"percentages\", \"problemType\": \"arithmetic\", \"hint\": \"To find the percentage, you can multiply 200 by 0.15.\"},\n",
        "]\n",
        "\n",
        "# --- GRU Model Definition ---\n",
        "class LearnerProfilerGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.3):\n",
        "        super(LearnerProfilerGRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.gru(packed_input)\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        output = self.fc(output)\n",
        "        output = self.sigmoid(output)\n",
        "        return output\n",
        "\n",
        "# --- Loading Functions ---\n",
        "@st.cache_resource(show_spinner=\"Warming up the AI engines...\")\n",
        "def load_all_models_and_artifacts():\n",
        "    device = torch.device('cpu')\n",
        "    drive_path = \"/content/drive/MyDrive/SocraticStreamlitApp/\"\n",
        "    profiler_model, scalers, mappings = None, None, None\n",
        "    try:\n",
        "        ml_base_path = drive_path + \"models\"\n",
        "        INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE = 8, 64, 4\n",
        "        profiler_model = LearnerProfilerGRU(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n",
        "        profiler_model.load_state_dict(torch.load(f\"{ml_base_path}/learner_profiler_gru.pth\", map_location=device))\n",
        "        profiler_model.eval()\n",
        "        with open(f\"{ml_base_path}/scalers.pkl\", 'rb') as f: scalers = pickle.load(f)\n",
        "        with open(f\"{ml_base_path}/mappings.pkl\", 'rb') as f: mappings = pickle.load(f)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading Learner Profiler: {e}\")\n",
        "\n",
        "    socratic_model, socratic_tokenizer = None, None\n",
        "    try:\n",
        "        adapter_path = drive_path + \"models/SLMs/socratic_tutor_phi3_unsloth_final\"\n",
        "        socratic_model, socratic_tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name=adapter_path, dtype=None, load_in_4bit=True\n",
        "        )\n",
        "        FastLanguageModel.for_inference(socratic_model)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading Socratic Tutor: {e}\")\n",
        "\n",
        "    return profiler_model, scalers, mappings, socratic_model, socratic_tokenizer\n",
        "\n",
        "# --- Inference Functions ---\n",
        "def predict_student_state(sequence_df, model, scalers, mappings):\n",
        "    if model is None or sequence_df.empty: return pd.DataFrame()\n",
        "    feature_order = ['skill_encoded', 'problemType_encoded', 'correct', 'attemptCount', 'totalHints', 'log_timeTaken', 'time_per_attempt', 'prev_correct']\n",
        "    processed_df = sequence_df.copy()\n",
        "    processed_df['skill_encoded'] = processed_df['skill'].apply(lambda x: mappings['skill'].get(x, -1))\n",
        "    processed_df['problemType_encoded'] = processed_df['problemType'].apply(lambda x: mappings['problemType'].get(x, -1))\n",
        "    for col in feature_order:\n",
        "        if col in scalers:\n",
        "            processed_df[col] = scalers[col].transform(processed_df[[col]])\n",
        "    feature_tensor = torch.tensor(processed_df[feature_order].values, dtype=torch.float32).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        prediction = model(feature_tensor, [len(processed_df)])\n",
        "    prediction_np = prediction.squeeze(0).cpu().numpy()\n",
        "    output_states = ['CONCENTRATING', 'GAMING', 'OFF TASK', 'BORED']\n",
        "    result_df = pd.DataFrame(prediction_np, columns=output_states)\n",
        "    result_df['Dominant State'] = result_df.idxmax(axis=1)\n",
        "    return result_df\n",
        "\n",
        "# --- (FIXED: Improved response processing to prevent prompt repetition) ---\n",
        "def get_socratic_feedback(tutor_model, tokenizer, dominant_state, question_text, user_answer, is_correct):\n",
        "    if tutor_model is None: return \"Error: Tutor model not loaded.\"\n",
        "\n",
        "    if is_correct:\n",
        "        prompt_content = f\"My student's dominant state is CONCENTRATING and they answered correctly.\\nProblem: '{question_text}'\\nCorrect Answer: {user_answer}\\nEngage them with an enrichment question.\"\n",
        "    else:\n",
        "        prompt_content = f\"The student's dominant state is {dominant_state}. They are on the problem '{question_text}' and their incorrect answer was {user_answer}. Guide them Socratically.\"\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_content}]\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = tutor_model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_new_tokens=60,\n",
        "            use_cache=True,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode the full output, then find and remove the exact prompt text\n",
        "    full_response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Use a precise string-based search to find the end of the prompt\n",
        "    prompt_marker = f\"user\\n{prompt_content}assistant\\n\"\n",
        "    response_start_index = full_response.find(prompt_marker)\n",
        "\n",
        "    if response_start_index != -1:\n",
        "        # Extract and clean the new text\n",
        "        response_text = full_response[response_start_index + len(prompt_marker):].strip()\n",
        "    else:\n",
        "        # Fallback to the previous split logic if the exact prompt isn't found\n",
        "        # This is a safety measure to prevent blank output.\n",
        "        response_text = full_response.split(\"assistant\\n\")[-1].strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "\n",
        "# --- User Authentication ---\n",
        "with open(\"/content/drive/MyDrive/SocraticStreamlitApp/config.yaml\") as file:\n",
        "    config = yaml.load(file, Loader=SafeLoader)\n",
        "authenticator = stauth.Authenticate(config['credentials'], config['cookie']['name'], config['cookie']['key'], config['cookie']['expiry_days'])\n",
        "authenticator.login()\n",
        "\n",
        "# --- Main Application Logic ---\n",
        "if st.session_state.get(\"authentication_status\"):\n",
        "    authenticator.logout('Logout', 'sidebar')\n",
        "    st.sidebar.title(f\"Welcome {st.session_state.get('name')}\")\n",
        "    profiler_model, scalers, mappings, socratic_model, socratic_tokenizer = load_all_models_and_artifacts()\n",
        "\n",
        "    if profiler_model is None or socratic_model is None:\n",
        "        st.error(\"A critical AI model failed to load. The application cannot continue.\")\n",
        "        st.stop()\n",
        "\n",
        "    def initialize_quiz():\n",
        "        st.session_state.session_sequence = []\n",
        "        st.session_state.prev_correct = 0\n",
        "        st.session_state.last_action_time = time.time()\n",
        "        st.session_state.problem_states = {q['id']: {'attempts': 0, 'hints': 0} for q in QUESTION_BANK}\n",
        "        st.session_state.socratic_dialogue = [{\"role\": \"assistant\", \"content\": \"Hello! I'm Euler, your Socratic Tutor. Let's solve some problems together.\"}]\n",
        "        st.session_state.user_answers = {q['id']: None for q in QUESTION_BANK}\n",
        "\n",
        "    if 'problem_states' not in st.session_state:\n",
        "        initialize_quiz()\n",
        "\n",
        "    st.title(\"Adaptive Socratic AI Tutor\")\n",
        "    st.write(\"---\")\n",
        "\n",
        "    main_col, profile_col = st.columns([2, 1])\n",
        "\n",
        "    with main_col:\n",
        "        st.subheader(\"Quiz Questions\")\n",
        "        for i, q in enumerate(QUESTION_BANK):\n",
        "            with st.container(border=True):\n",
        "                st.latex(q['latex'])\n",
        "                st.session_state.user_answers[q['id']] = st.number_input(\"Your Answer:\", key=f\"ans_{q['id']}\", step=None, value=st.session_state.user_answers.get(q['id']), format=\"%.3f\")\n",
        "\n",
        "                submit_col, hint_col = st.columns(2)\n",
        "                with submit_col:\n",
        "                    if st.button(\"Submit Answer\", key=f\"submit_{q['id']}\"):\n",
        "                        time_taken = time.time() - st.session_state.last_action_time\n",
        "                        st.session_state.problem_states[q['id']]['attempts'] += 1\n",
        "                        user_answer = st.session_state.user_answers.get(q['id'])\n",
        "                        is_correct = 1 if user_answer is not None and abs(user_answer - q['answer']) < 0.001 else 0\n",
        "\n",
        "                        current_action = { 'skill': q['skill'], 'problemType': q['problemType'], 'correct': is_correct, 'attemptCount': st.session_state.problem_states[q['id']]['attempts'], 'totalHints': st.session_state.problem_states[q['id']]['hints'], 'timeTaken_capped_95': min(time_taken, 113.0), 'prev_correct': st.session_state.prev_correct }\n",
        "                        current_action['log_timeTaken'] = np.log(current_action['timeTaken_capped_95'] + 1)\n",
        "                        current_action['time_per_attempt'] = current_action['timeTaken_capped_95'] / current_action[\"attemptCount\"] if current_action[\"attemptCount\"] > 0 else 0\n",
        "\n",
        "                        st.session_state.session_sequence.append(current_action)\n",
        "                        st.session_state.prev_correct = is_correct\n",
        "                        st.session_state.last_action_time = time.time()\n",
        "\n",
        "                        sequence_df = pd.DataFrame(st.session_state.session_sequence)\n",
        "                        predictions_df = predict_student_state(sequence_df, profiler_model, scalers, mappings)\n",
        "\n",
        "                        if not predictions_df.empty:\n",
        "                            dominant_state = predictions_df['Dominant State'].iloc[-1]\n",
        "                            with st.spinner(\"Tutor is thinking...\"):\n",
        "                                # --- (FIX 1 Cont'd: Pass the clean 'text' version to the tutor) ---\n",
        "                                feedback = get_socratic_feedback(socratic_model, socratic_tokenizer, dominant_state, q['text'], user_answer, is_correct)\n",
        "\n",
        "                            # --- (FIX 1 Cont'd: Use clean text in the dialogue for better readability) ---\n",
        "                            user_log_message = f\"Regarding '{q['text']}', my answer was {user_answer}.\"\n",
        "                            st.session_state.socratic_dialogue.append({\"role\": \"user\", \"content\": user_log_message})\n",
        "                            st.session_state.socratic_dialogue.append({\"role\": \"assistant\", \"content\": feedback})\n",
        "                        else:\n",
        "                            st.warning(\"Learner Profiler could not make a prediction.\")\n",
        "\n",
        "                with hint_col:\n",
        "                    if st.button(\"Get a Hint\", key=f\"hint_{q['id']}\"):\n",
        "                        st.session_state.problem_states[q['id']]['hints'] += 1\n",
        "                        st.info(q['hint'])\n",
        "                        st.session_state.socratic_dialogue.append({\"role\": \"user\", \"content\": f\"I need a hint for Q{i+1}.\"})\n",
        "                        st.session_state.socratic_dialogue.append({\"role\": \"assistant\", \"content\": f\"Of course! Here is a hint: {q['hint']}\"})\n",
        "\n",
        "    with profile_col:\n",
        "        st.subheader(\"Socratic Tutor Dialogue\")\n",
        "        dialogue_container = st.container(height=300, border=True)\n",
        "        for message in st.session_state.socratic_dialogue:\n",
        "            with dialogue_container.chat_message(name=message[\"role\"], avatar=\"ğŸ§‘â€ğŸ“\" if message[\"role\"] == \"user\" else \"ğŸ¤–\"):\n",
        "                st.markdown(message[\"content\"])\n",
        "\n",
        "        st.subheader(\"Learner Profile Analysis\")\n",
        "        if st.session_state.session_sequence:\n",
        "            sequence_df = pd.DataFrame(st.session_state.session_sequence)\n",
        "            predictions_df = predict_student_state(sequence_df, profiler_model, scalers, mappings)\n",
        "            if not predictions_df.empty:\n",
        "                display_df = pd.concat([sequence_df[['correct', 'attemptCount', 'totalHints']].reset_index(drop=True), predictions_df], axis=1)\n",
        "                st.dataframe(display_df, use_container_width=True)\n",
        "                latest_state = display_df['Dominant State'].iloc[-1]\n",
        "                st.metric(\"Current Inferred State\", latest_state)\n",
        "\n",
        "    if st.sidebar.button(\"Restart Quiz\"):\n",
        "        for key in list(st.session_state.keys()):\n",
        "            if key not in ['authentication_status', 'name', 'username']:\n",
        "                del st.session_state[key]\n",
        "        st.rerun()\n",
        "\n",
        "elif st.session_state.get(\"authentication_status\") is False:\n",
        "    st.error('Username/password is incorrect')\n",
        "elif st.session_state.get(\"authentication_status\") is None:\n",
        "    st.warning('Please enter your username and password')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4trHju68Yb_7",
        "outputId": "a3e27e1e-9f26-4776-8b17-77372b24dd45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing AdaptiveBehaviorSocraticTutor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ğŸ”‘ Set your ngrok token\n",
        "ngrok.set_auth_token(\"32JHw7K42RZkMGo9VKVqMmNPqa4_6FxGCF8PmZghJPJqE8y3N\")\n",
        "\n",
        "def start_streamlit(filename=\"AdaptiveBehaviorSocraticTutor.py\", port=8501):\n",
        "    \"\"\"Run any Streamlit app file in Colab and expose via ngrok\"\"\"\n",
        "    # Kill old tunnels\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Start Streamlit in background\n",
        "    get_ipython().system_raw(f\"streamlit run {filename} --server.port {port} &\")\n",
        "\n",
        "    # Wait for Streamlit to boot\n",
        "    time.sleep(3)\n",
        "\n",
        "    # Create new tunnel\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(f\"ğŸŒ {filename} is live at: {public_url}\")\n",
        "\n",
        "# Example usage\n",
        "start_streamlit(\"AdaptiveBehaviorSocraticTutor.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9InUsZXEYkBj",
        "outputId": "9714d4cc-68fe-414b-e4c3-7b416427fbbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ AdaptiveBehaviorSocraticTutor.py is live at: NgrokTunnel: \"https://eafebf79504f.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}